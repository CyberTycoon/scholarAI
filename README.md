# 🧠 Research Assistant — Privacy-First AI Knowledge Engine

**Research Assistant** is a blazing-fast, privacy-focused AI research tool that runs locally via [Ollama](https://ollama.com/) or securely in the cloud. Designed for thinkers, writers, developers, analysts, and researchers, it offers total control over data and models — without sacrificing intelligence or usability.

> 🛡️ Your prompts stay local. Your research stays yours.

---

## 🚀 Features

- ✅ **Runs Locally or in the Cloud**
  - Use local models via `Ollama` (e.g., LLaMA, Mistral, Phi-3, etc.)
  - Or use our cloud-based LLM endpoints for enhanced context

- 🔐 **Privacy-First**
  - No prompt logging or background data sync
  - Local model support

- 🧠 **Powerful Research Tools**
  - Citation-aware summarization
  - Paper analysis, code explanation, data interpretation
  - Multilingual input/output support
  - File input support

- 💾 **Modular Architecture**
  - Plug-and-play with any local model (via Ollama)
  - Just research with our cloud model

- 🎯 **Built for Precision & Control**
  - Real-time inference
  - Custom prompt engineering
  - User-defined contexts & memory

---

## 📦 Tech Stack

- **Frontend:** Nextjs + Tailwind + Framer Motion
- **Backend:** completely serverless 
- **LLM Interface:** Ollama for local model inference and gemini for cloud model
- **Persistence:** LocalStorage / IndexedDB / Encrypted SQLite (soon)



