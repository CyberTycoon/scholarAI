# ğŸ§  Research Assistant â€” Privacy-First AI Knowledge Engine

**Research Assistant** is a blazing-fast, privacy-focused AI research tool that runs locally via [Ollama](https://ollama.com/) or securely in the cloud. Designed for thinkers, writers, developers, analysts, and researchers, it offers total control over data and models â€” without sacrificing intelligence or usability.

> ğŸ›¡ï¸ Your prompts stay local. Your research stays yours.

---

## ğŸš€ Features

- âœ… **Runs Locally or in the Cloud**
  - Use local models via `Ollama` (e.g., LLaMA, Mistral, Phi-3, etc.)
  - Or use our cloud-based LLM endpoints for enhanced context

- ğŸ” **Privacy-First**
  - No prompt logging or background data sync
  - Local model support

- ğŸ§  **Powerful Research Tools**
  - Citation-aware summarization
  - Paper analysis, code explanation, data interpretation
  - Multilingual input/output support
  - File input support

- ğŸ’¾ **Modular Architecture**
  - Plug-and-play with any local model (via Ollama)
  - Just research with our cloud model

- ğŸ¯ **Built for Precision & Control**
  - Real-time inference
  - Custom prompt engineering
  - User-defined contexts & memory

---

## ğŸ“¦ Tech Stack

- **Frontend:** Nextjs + Tailwind + Framer Motion
- **Backend:** completely serverless 
- **LLM Interface:** Ollama for local model inference and gemini for cloud model
- **Persistence:** LocalStorage / IndexedDB / Encrypted SQLite (soon)



